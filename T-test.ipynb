{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Score(X,num_obj_cat):\n",
    "    \"\"\"\n",
    "    IN:\n",
    "    X: [N,M] array, where M is the number of features and N the number of objects.\n",
    "    num_obj_cat: array containing number of objects for each class\n",
    "\n",
    "    OUT:\n",
    "    Tc: Scatter distance\n",
    "    \"\"\"\n",
    "\n",
    "    [numSamples,Dim] = X.shape\n",
    "\n",
    "    numCat = num_obj_cat.size\n",
    "\n",
    "    u = np.mean(X,axis=0)\n",
    "    s = np.std(X,axis=0,ddof=1)\n",
    "\n",
    "    B = X - u\n",
    "    Z = B/s\n",
    "\n",
    "\n",
    "    ind = np.cumsum(num_obj_cat)\n",
    "    ind = np.concatenate(([0],ind))\n",
    "\n",
    "    uCat = np.zeros([numCat,Dim])\n",
    "    for k in range(numCat):\n",
    "        data_class = Z[ind[k]:ind[k+1]]\n",
    "        uCat[k] = np.mean(data_class,axis=0)\n",
    "\n",
    "    X_aux = Z.copy()\n",
    "    for k in range(numCat):\n",
    "        X_aux[ind[k]:ind[k+1]] -=  uCat[k]\n",
    "\n",
    "    Sw = np.zeros([Dim,Dim]) # Within-cluster scatter matrix\n",
    "    Sb = np.zeros([Dim,Dim]) # Between-cluster scatter matrix\n",
    "    for k in range(numCat):\n",
    "        data_class = X_aux[ind[k]:ind[k+1]]\n",
    "\n",
    "        Sw += np.dot(data_class.T,data_class) \n",
    "\n",
    "        aux = (uCat[k]-0.).reshape([1,Dim])\n",
    "        Sb += num_obj_cat[k]*np.dot(aux.T,aux)\n",
    "\n",
    "\n",
    "    C = np.dot(np.linalg.inv(Sw),Sb)\n",
    "    Tc = np.trace(C)\n",
    "\n",
    "    return Tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_original_breakpoints(samples_breakpoints,n):\n",
    "    samples_breakpoints = open(samples_breakpoints,'r').read().split('\\n')[:-1]\n",
    "    total_series = len(samples_breakpoints)\n",
    "    slopes = []\n",
    "    breakpoints = []\n",
    "    preds = []\n",
    "    idxs = []\n",
    "    for i in range(0,total_series,4):\n",
    "        idx = int(samples_breakpoints[i]) - 1\n",
    "        \n",
    "        slopes_i = [float(n) for n in samples_breakpoints[i+1].split(' ')]\n",
    "        breakpoints_i = [float(n) for n in samples_breakpoints[i+2].split(' ')]\n",
    "        preds_i = [float(n) for n in samples_breakpoints[i+3].split(' ')]\n",
    "        if len(slopes_i) == n:\n",
    "            idxs.append(idx)\n",
    "            slopes.append(np.asarray(slopes_i))\n",
    "            breakpoints.append(np.asarray(breakpoints_i))\n",
    "            preds.append(np.asarray(preds_i))\n",
    "    \n",
    "    return np.asarray(idxs),np.asarray(slopes),np.asarray(breakpoints),np.asarray(preds)\n",
    "\n",
    "def read_file(samples_breakpoints):\n",
    "    samples_breakpoints = open(samples_breakpoints,'r').read().split('\\n')[:-1]\n",
    "    total_series = len(samples_breakpoints)\n",
    "    slopes = []\n",
    "    breakpoints = []\n",
    "    idxs = []\n",
    "    for i in range(0,total_series,3):\n",
    "        idx = int(samples_breakpoints[i]) - 1\n",
    "        \n",
    "        slopes_i = [float(n) for n in samples_breakpoints[i+1].split(' ')]\n",
    "        breakpoints_i = [float(n) for n in samples_breakpoints[i+2].split(' ')]\n",
    "        # breakpoints_i.append(1.0)\n",
    "\n",
    "        idxs.append(idx)\n",
    "        slopes.append(np.asarray(slopes_i))\n",
    "        breakpoints.append(np.asarray(breakpoints_i))\n",
    "    \n",
    "    return np.asarray(idxs),np.asarray(slopes),np.asarray(breakpoints)\n",
    "\n",
    "def breakpoints2intervals(x):\n",
    "    intervals = [x[0]]\n",
    "    for i in range(len(x)-1):\n",
    "        intervals.append(x[i+1]-x[i])\n",
    "    intervals.append(1-x[-1])\n",
    "    return intervals\n",
    "\n",
    "def norm_data(slopes_original,intervals_original,slopes_artificial,intervals_artificial):\n",
    "    original_data = np.concatenate((slopes_original,intervals_original),axis=1)\n",
    "    artificial_data = np.concatenate((slopes_artificial,intervals_artificial),axis=1)\n",
    "    all_data = np.concatenate((original_data,artificial_data),axis=0)\n",
    "\n",
    "    m = np.mean(all_data,axis=0)\n",
    "    std = np.std(all_data,axis=0)\n",
    "    original_data = (original_data - m)/std\n",
    "    artificial_data = (artificial_data -m)/std\n",
    "    \n",
    "    all_data = (all_data - m)/std\n",
    "    return original_data,artificial_data,all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = sorted(glob.glob('data/plos_one_artificial_*.txt'))\n",
    "original_data_filename = 'data/plos_one_total_breakpoints_k4it.max100stop.if.errorFALSE_original_data_filtered.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/plos_one_artificial_all_random_2.txt',\n",
       " 'data/plos_one_artificial_all_random_3.txt',\n",
       " 'data/plos_one_artificial_all_random_4.txt',\n",
       " 'data/plos_one_artificial_all_random_5.txt',\n",
       " 'data/plos_one_artificial_intervals_slope_axis0_2.txt',\n",
       " 'data/plos_one_artificial_intervals_slope_axis0_3.txt',\n",
       " 'data/plos_one_artificial_intervals_slope_axis0_4.txt',\n",
       " 'data/plos_one_artificial_intervals_slope_axis0_5.txt',\n",
       " 'data/plos_one_artificial_intervals_slope_random_2.txt',\n",
       " 'data/plos_one_artificial_intervals_slope_random_3.txt',\n",
       " 'data/plos_one_artificial_intervals_slope_random_4.txt',\n",
       " 'data/plos_one_artificial_intervals_slope_random_5.txt',\n",
       " 'data/plos_one_artificial_intervals_slopes_2.txt',\n",
       " 'data/plos_one_artificial_intervals_slopes_3.txt',\n",
       " 'data/plos_one_artificial_intervals_slopes_4.txt',\n",
       " 'data/plos_one_artificial_intervals_slopes_5.txt',\n",
       " 'data/plos_one_artificial_slopes_interval_axis0_2.txt',\n",
       " 'data/plos_one_artificial_slopes_interval_axis0_3.txt',\n",
       " 'data/plos_one_artificial_slopes_interval_axis0_4.txt',\n",
       " 'data/plos_one_artificial_slopes_interval_axis0_5.txt',\n",
       " 'data/plos_one_artificial_slopes_interval_random_2.txt',\n",
       " 'data/plos_one_artificial_slopes_interval_random_3.txt',\n",
       " 'data/plos_one_artificial_slopes_interval_random_4.txt',\n",
       " 'data/plos_one_artificial_slopes_interval_random_5.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/plos_one_artificial_all_random_2.txt\n",
      "0.12632442088739662\n",
      "data/plos_one_artificial_all_random_3.txt\n",
      "0.787159695435364\n",
      "data/plos_one_artificial_all_random_4.txt\n",
      "2.6270670867630628\n",
      "data/plos_one_artificial_all_random_5.txt\n",
      "4.9476059642318715\n",
      "data/plos_one_artificial_intervals_slope_axis0_2.txt\n",
      "0.0001137556129124228\n",
      "data/plos_one_artificial_intervals_slope_axis0_3.txt\n",
      "0.00010705796349294838\n",
      "data/plos_one_artificial_intervals_slope_axis0_4.txt\n",
      "0.0001335999793633252\n",
      "data/plos_one_artificial_intervals_slope_axis0_5.txt\n",
      "3.0397153659597633e-05\n",
      "data/plos_one_artificial_intervals_slope_random_2.txt\n",
      "0.08709669651555463\n",
      "data/plos_one_artificial_intervals_slope_random_3.txt\n",
      "0.42244704467550637\n",
      "data/plos_one_artificial_intervals_slope_random_4.txt\n",
      "0.3621055456594155\n",
      "data/plos_one_artificial_intervals_slope_random_5.txt\n",
      "0.283289090080468\n",
      "data/plos_one_artificial_intervals_slopes_2.txt\n",
      "6.854462299098515e-05\n",
      "data/plos_one_artificial_intervals_slopes_3.txt\n",
      "8.749954547236636e-05\n",
      "data/plos_one_artificial_intervals_slopes_4.txt\n",
      "0.00021583858579023938\n",
      "data/plos_one_artificial_intervals_slopes_5.txt\n",
      "9.330936882686122e-05\n",
      "data/plos_one_artificial_slopes_interval_axis0_2.txt\n",
      "1.8532851205978022e-05\n",
      "data/plos_one_artificial_slopes_interval_axis0_3.txt\n",
      "7.470219710439477e-05\n",
      "data/plos_one_artificial_slopes_interval_axis0_4.txt\n",
      "5.9375842181737854e-05\n",
      "data/plos_one_artificial_slopes_interval_axis0_5.txt\n",
      "9.411974776031506e-05\n",
      "data/plos_one_artificial_slopes_interval_random_2.txt\n",
      "0.09253710963308018\n",
      "data/plos_one_artificial_slopes_interval_random_3.txt\n",
      "0.2368173268529092\n",
      "data/plos_one_artificial_slopes_interval_random_4.txt\n",
      "0.14442363889427867\n",
      "data/plos_one_artificial_slopes_interval_random_5.txt\n",
      "0.08198580273845456\n"
     ]
    }
   ],
   "source": [
    "for f in filenames:\n",
    "    print(f)\n",
    "    n = int(f.split('_')[-1].split('.txt')[0])\n",
    "    _,slopes,breakpoints,_ = read_original_breakpoints(original_data_filename,n)\n",
    "    slopes_original = np.asarray([(np.arctan(s)*57.2958) for s in slopes])\n",
    "    intervals_original = np.asarray([np.asarray(breakpoints2intervals(b)) for b in breakpoints])\n",
    "#     print(slopes_original[:10])\n",
    "#     print(intervals_original[:10])\n",
    "    \n",
    "    _,slopes_artificial,intervals_artificial = read_file(f)\n",
    "#     print(slopes_artificial[:10])\n",
    "#     print(intervals_artificial[:10])\n",
    "\n",
    "    original,artificial,all_data = norm_data(slopes_original,intervals_original,slopes_artificial,intervals_artificial)\n",
    "    print(Score(all_data,np.array([len(original),len(artificial)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
