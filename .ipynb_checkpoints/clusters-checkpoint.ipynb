{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from analise_breakpoints import read_file,read_file_original\n",
    "from analise_breakpoints import breakpoints2intervals\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_n_clusters(range_n_clusters,X,alg,name):\n",
    "    for n_clusters in range_n_clusters:\n",
    "        # Create a subplot with 1 row and 2 columns\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        fig.set_size_inches(18, 7)\n",
    "\n",
    "        ax1.set_xlim([-0.1, 1])\n",
    "        ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "        \n",
    "        clusterer = alg(n_clusters=n_clusters)\n",
    "        cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "        silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "        print(\"For n_clusters =\", n_clusters,\n",
    "            \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "        sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "        y_lower = 10\n",
    "        for i in range(n_clusters):\n",
    "            ith_cluster_silhouette_values = \\\n",
    "                sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "            ith_cluster_silhouette_values.sort()\n",
    "\n",
    "            size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "\n",
    "            color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "            ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                            0, ith_cluster_silhouette_values,\n",
    "                            facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "            # Label the silhouette plots with their cluster numbers at the middle\n",
    "            ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "            # Compute the new y_lower for next plot\n",
    "            y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "        ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "        ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "        ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "        # The vertical line for average silhouette score of all the values\n",
    "        ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "        ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "        ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "        # 2nd Plot showing the actual clusters formed\n",
    "        colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "        pca = PCA(n_components=2)\n",
    "        pca.fit(X)\n",
    "        X1 = pca.transform(X)\n",
    "        ax2.scatter(X1[:, 0], X1[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                    c=colors, edgecolor='k')\n",
    "\n",
    "        ax2.set_title(\"The visualization of the clustered data.\")\n",
    "        ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "        ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "        \n",
    "        plt.suptitle((\"Silhouette analysis for AgglomerativeClustering on sample data \"\n",
    "                    \"with n_clusters = %d\" % n_clusters),\n",
    "                    fontsize=14, fontweight='bold')\n",
    "        plt.savefig(name+'_'+str(n_clusters)+'.pdf',format='pdf')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values_by_label(ktotal,alg,X):\n",
    "    kmeans = alg(n_clusters=ktotal)\n",
    "    kmeans.fit(X)\n",
    "    labels = kmeans.predict(X)\n",
    "    intervals_by_label = dict()\n",
    "    for i in range(ktotal):\n",
    "        intervals_by_label[i] = []\n",
    "    for l,x in zip(labels,X):\n",
    "        intervals_by_label[l].append(x)\n",
    "\n",
    "    return intervals_by_label\n",
    "\n",
    "def plot_lines_blox_plot(intervals_by_label,ktotal,dim=8):\n",
    "    fig1 = plt.figure(figsize=(4,2*(ktotal+1)))\n",
    "    fig = plt.figure(figsize=(8,4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    x = [i for i in range(dim)]\n",
    "\n",
    "    colors = {0:'blue',1:'red',2:'green',3:'orange',4:'gray',5:'cyan',6:'magenta'}\n",
    "\n",
    "    for k,xs in intervals_by_label.items():\n",
    "        xs = np.asarray([np.asarray(z) for z in xs])\n",
    "        d = describe(xs,axis=0)\n",
    "        means = d.mean\n",
    "        stds = np.sqrt(d.variance)\n",
    "\n",
    "        ax.errorbar(x,means,yerr=stds,fmt='-o',label=str(k)+'(mean w/ std)',c=colors[k],alpha=0.8)\n",
    "        \n",
    "        nx = xs.shape[1]\n",
    "        data_to_boxplot = []\n",
    "        for i in range(nx):\n",
    "            data_to_boxplot.append(xs[:,i])\n",
    "        ax1 = fig1.add_subplot(ktotal,1,k+1)\n",
    "        ax1.boxplot(data_to_boxplot,boxprops=dict(color=colors[k],alpha=0.7))\n",
    "        # ax.plot(x,mins,label=str(k)+' (mins)',c=colors[k],alpha=0.5)\n",
    "        # ax.plot(x,maxs,label=str(k)+' (maxs)',c=colors[k],alpha=0.5)\n",
    "\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(1, 1), ncol=1)\n",
    "    ax.set_xticks(x,[str(k) for k in x])\n",
    "    ax.set_xlabel('intervals')\n",
    "    fig.tight_layout()\n",
    "    fig1.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(164976,) (43738, 4)\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b69407d178f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# DADOS NORMALIZADOS POR TODOS OS DADOS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0moriginal_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslopes_original\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mintervals_original\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0martificial_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslopes_artificial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mintervals_artificial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0martificial_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "# range_n_clusters = [2, 3, 4, 5, 6]\n",
    "# test_n_clusters(range_n_clusters,X,KMeans,'kmeans')\n",
    "\n",
    "# idxs,slopes_artificial,intervals_artificial,preds = read_file(samples_breakpoints='data/plos_one_total_breakpoints_k4_original_data_filtered.txt')\n",
    "# intervals_artificial = np.asarray(intervals_artificial)\n",
    "slopes_original,breakpoints_original = read_file_original('data/plos_one_data_total.txt')\n",
    "intervals_original = np.asarray([breakpoints2intervals(b) for b in breakpoints_original])\n",
    "\n",
    "print(slopes_original.shape,slopes_artificial.shape)\n",
    "\n",
    "# DADOS NORMALIZADOS POR TODOS OS DADOS\n",
    "original_data = np.concatenate((slopes_original,intervals_original),axis=1)\n",
    "artificial_data = np.concatenate((slopes_artificial,intervals_artificial),axis=1)\n",
    "all_data = np.concatenate((original_data,artificial_data),axis=0)\n",
    "\n",
    "m = np.mean(all_data,axis=0)\n",
    "std = np.std(all_data,axis=0)\n",
    "original_data = (original_data - m)/std\n",
    "artificial_data = (artificial_data -m)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ktotal = 3\n",
    "alg = KMeans\n",
    "intervals_by_label = get_values_by_label(ktotal,alg,original_data)\n",
    "plot_lines_blox_plot(intervals_by_label,ktotal)\n",
    "\n",
    "plt.scatter(original_data[:, 4], original_data[:, 6], marker='.', s=30, lw=0, alpha=0.7)\n",
    "plt.xlabel('interval 1')\n",
    "plt.ylabel('interval 2')\n",
    "plt.show()\n",
    "\n",
    "# pca usando todos os dados OK\n",
    "# clusters usando todo os dados\n",
    "# sinais aleatórios para comparar os originais OK\n",
    "# angulos diferentes e intervalos probabilisticos OK\n",
    "# visualizar intervalos 1 e 3 OK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
